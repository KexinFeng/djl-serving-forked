
processing spec_length = 10, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 400
seq_thru_put: 0.924 reqs/sec, 
token_latency: 10.8 ms/token 
Peak memory usage (MiB): 70711.1728515625
Peak memory usage (including context) (MiB): 80302.0625
Avg accp length: 4.2input_size: 10
avg_time: 4.33,

processing spec_length = 9, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 400
seq_thru_put: 0.956 reqs/sec, 
token_latency: 10.5 ms/token 
Peak memory usage (MiB): 70709.9521484375
Peak memory usage (including context) (MiB): 80302.0625
Avg accp length: 4.0input_size: 10
avg_time: 4.18,

processing spec_length = 8, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 400
seq_thru_put: 1.02 reqs/sec, 
token_latency: 9.8 ms/token 
Peak memory usage (MiB): 70708.9814453125
Peak memory usage (including context) (MiB): 80302.0625
Avg accp length: 3.8input_size: 10
avg_time: 3.92,

processing spec_length = 7, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 400
seq_thru_put: 1.06 reqs/sec, 
token_latency: 9.39 ms/token 
Peak memory usage (MiB): 70708.5810546875
Peak memory usage (including context) (MiB): 80302.0625
Avg accp length: 3.6input_size: 10
avg_time: 3.76,

processing spec_length = 6, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 400
seq_thru_put: 1.06 reqs/sec, 
token_latency: 9.4 ms/token 
Peak memory usage (MiB): 70706.80078125
Peak memory usage (including context) (MiB): 80302.0625
Avg accp length: 3.4input_size: 10
avg_time: 3.76,

processing spec_length = 5, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 400
seq_thru_put: 1.16 reqs/sec, 
token_latency: 8.65 ms/token 
Peak memory usage (MiB): 70706.75244140625
Peak memory usage (including context) (MiB): 80302.0625
Avg accp length: 3.2input_size: 10
avg_time: 3.46,

processing spec_length = 4, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 400
seq_thru_put: 1.3 reqs/sec, 
token_latency: 7.72 ms/token 
Peak memory usage (MiB): 70705.341796875
Peak memory usage (including context) (MiB): 80302.0625
Avg accp length: 2.8input_size: 10
avg_time: 3.09,

processing spec_length = 3, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 400
seq_thru_put: 1.19 reqs/sec, 
token_latency: 8.4 ms/token 
Peak memory usage (MiB): 70705.0552734375
Peak memory usage (including context) (MiB): 80302.0625
Avg accp length: 2.3input_size: 10
avg_time: 3.36,

processing spec_length = 2, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 400
seq_thru_put: 0.993 reqs/sec, 
token_latency: 10.1 ms/token 
Peak memory usage (MiB): 70706.33935546875
Peak memory usage (including context) (MiB): 80300.0625
Avg accp length: 1.8input_size: 10
avg_time: 4.03,

processing spec_length = 1, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 400
seq_thru_put: 0.675 reqs/sec, 
token_latency: 14.8 ms/token 
Peak memory usage (MiB): 70705.65478515625
Peak memory usage (including context) (MiB): 80300.0625
Avg accp length: 1.0input_size: 10
avg_time: 5.93,

processing spec_length = 0, draft_model = None .... 
tot_gen_tokens: 400
seq_thru_put: 1.37 reqs/sec, 
token_latency: 7.3 ms/token 
Peak memory usage (MiB): 77308.2861328125
Peak memory usage (including context) (MiB): 80206.0625
Avg accp length: 1.0input_size: 10
avg_time: 2.92,
saved to /opt/mount_folder/djl-serving-forked/engines/python/setup/djl_python/tests/rolling_batch_test_scripts/data_v2_2/lmi_perform_concur_4+Llama-2-13B-Chat-fp16++TinyLlama-1.1B-Chat-v0.6.p
Time elapse: 299.9027998219972s
