
processing spec_length = 1 .... 
tot_gen_tokens: 6400
seq_thru_put: 5.96 reqs/sec, 
token_latency: 1.68 ms/token 
Peak memory usage (MiB): 19249.9453125
Peak memory usage (including context) (MiB): 20698.0
Avg accp length: 1.0input_size: 1
avg_time: 10.729952004667817,

processing spec_length = 0 .... 
tot_gen_tokens: 6400
seq_thru_put: 9.09 reqs/sec, 
token_latency: 1.1 ms/token 
Peak memory usage (MiB): 19205.36767578125
Peak memory usage (including context) (MiB): 19584.0
Avg accp length: 1.0input_size: 1
avg_time: 7.037046016334595,
saved to /opt/mount_folder/djl-serving/engines/python/setup/djl_python/tests/rolling_batch_test_scripts/data/lmi_perform+Llama-2-7B-Chat-fp16++TinyLlama-1.1B-Chat-v0.6_concur_64.p
Time elapse: 73.82384169800207s
