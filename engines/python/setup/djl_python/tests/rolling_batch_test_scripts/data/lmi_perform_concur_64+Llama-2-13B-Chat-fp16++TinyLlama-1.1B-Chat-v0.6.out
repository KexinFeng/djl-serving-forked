
processing spec_length = 10, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 6400
seq_thru_put: 8.3 reqs/sec, 
token_latency: 1.2 ms/token 
Peak memory usage (MiB): 60317.233072916664
Peak memory usage (including context) (MiB): 80908.3125
Avg accp length: 4.2input_size: 10
avg_time: 7.71,

processing spec_length = 9, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 6400
seq_thru_put: 8.6 reqs/sec, 
token_latency: 1.16 ms/token 
Peak memory usage (MiB): 60297.229654947914
Peak memory usage (including context) (MiB): 80888.3125
Avg accp length: 4.0input_size: 10
avg_time: 7.44,

processing spec_length = 8, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 6400
seq_thru_put: 9.12 reqs/sec, 
token_latency: 1.1 ms/token 
Peak memory usage (MiB): 60277.228190104164
Peak memory usage (including context) (MiB): 80802.3125
Avg accp length: 3.8input_size: 10
avg_time: 7.02,

processing spec_length = 7, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 6400
seq_thru_put: 9.67 reqs/sec, 
token_latency: 1.03 ms/token 
Peak memory usage (MiB): 60255.913248697914
Peak memory usage (including context) (MiB): 80790.3125
Avg accp length: 3.7input_size: 10
avg_time: 6.62,

processing spec_length = 6, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 6400
seq_thru_put: 10.2 reqs/sec, 
token_latency: 0.978 ms/token 
Peak memory usage (MiB): 60236.097330729164
Peak memory usage (including context) (MiB): 80772.3125
Avg accp length: 3.4input_size: 10
avg_time: 6.26,

processing spec_length = 5, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 6400
seq_thru_put: 11.3 reqs/sec, 
token_latency: 0.886 ms/token 
Peak memory usage (MiB): 60216.757486979164
Peak memory usage (including context) (MiB): 80762.3125
Avg accp length: 3.2input_size: 10
avg_time: 5.67,

processing spec_length = 4, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 6400
seq_thru_put: 11.3 reqs/sec, 
token_latency: 0.888 ms/token 
Peak memory usage (MiB): 60209.201822916664
Peak memory usage (including context) (MiB): 80722.3125
Avg accp length: 2.8input_size: 10
avg_time: 5.68,

processing spec_length = 3, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 6400
seq_thru_put: 10.6 reqs/sec, 
token_latency: 0.939 ms/token 
Peak memory usage (MiB): 60209.2001953125
Peak memory usage (including context) (MiB): 80706.3125
Avg accp length: 2.4input_size: 10
avg_time: 6.01,

processing spec_length = 2, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 6400
seq_thru_put: 9.73 reqs/sec, 
token_latency: 1.03 ms/token 
Peak memory usage (MiB): 60209.19873046875
Peak memory usage (including context) (MiB): 80706.3125
Avg accp length: 1.8input_size: 10
avg_time: 6.58,

processing spec_length = 1, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 6400
seq_thru_put: 7.13 reqs/sec, 
token_latency: 1.4 ms/token 
Peak memory usage (MiB): 60209.19775390625
Peak memory usage (including context) (MiB): 80704.3125
Avg accp length: 1.0input_size: 10
avg_time: 8.98,

processing spec_length = 0, draft_model = None .... 
tot_gen_tokens: 6400
seq_thru_put: 13.2 reqs/sec, 
token_latency: 0.758 ms/token 
Peak memory usage (MiB): 75493.85693359375
Peak memory usage (including context) (MiB): 80446.3125
Avg accp length: 1.0input_size: 10
avg_time: 4.85,
saved to /opt/mount_folder/djl-serving-forked/engines/python/setup/djl_python/tests/rolling_batch_test_scripts/data/lmi_perform_concur_64+Llama-2-13B-Chat-fp16++TinyLlama-1.1B-Chat-v0.6.p
Time elapse: 300.0096466929972s
