
processing spec_length = 0 .... 
seq_thru_put: 0.281 reqs/sec, 
token_latency: 36 ms/token 
Peak memory usage (MiB): 19142.33154296875
Peak memory usage (including context) (MiB): 19598.0

avg_time: 3.597063908663889,tot_gen_tokens: 100


processing spec_length = 1 .... 
seq_thru_put: 0.174 reqs/sec, 
token_latency: 57.4 ms/token 
Peak memory usage (MiB): 19106.7109375
Peak memory usage (including context) (MiB): 19440.0

avg_time: 5.74473584566537,tot_gen_tokens: 100


processing spec_length = 2 .... 
seq_thru_put: 0.252 reqs/sec, 
token_latency: 40 ms/token 
Peak memory usage (MiB): 19106.7490234375
Peak memory usage (including context) (MiB): 19440.0

avg_time: 3.997574777000409,tot_gen_tokens: 100


processing spec_length = 3 .... 
seq_thru_put: 0.321 reqs/sec, 
token_latency: 31.4 ms/token 
Peak memory usage (MiB): 19106.94140625
Peak memory usage (including context) (MiB): 19440.0

avg_time: 3.137114772335432,tot_gen_tokens: 100


processing spec_length = 4 .... 
seq_thru_put: 0.287 reqs/sec, 
token_latency: 35.2 ms/token 
Peak memory usage (MiB): 19107.1708984375
Peak memory usage (including context) (MiB): 19440.0

avg_time: 3.5232071166659202,tot_gen_tokens: 100

saved to /opt/mount_folder/djl-serving/engines/python/setup/djl_python/tests/rolling_batch_test_scripts/data/lmi_perform_benchmark_Llama++TinyL.p
Time elapse: 123.69541384900367s
