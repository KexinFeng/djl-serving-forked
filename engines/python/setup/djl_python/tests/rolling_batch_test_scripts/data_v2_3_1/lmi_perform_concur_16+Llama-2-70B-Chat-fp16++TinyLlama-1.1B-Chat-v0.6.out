
processing spec_length = 7, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 4096
seq_thru_put: 0.46 reqs/sec, 
token_latency: 8.49 ms/token 
Peak memory usage (MiB): 21541.093098958332
Peak memory usage (including context) (MiB): 22310.0
Avg accp length: 3.7 
input_size: 7
avg_time: 34.79,

processing spec_length = 6, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 4096
seq_thru_put: 0.487 reqs/sec, 
token_latency: 8.03 ms/token 
Peak memory usage (MiB): 21541.093098958332
Peak memory usage (including context) (MiB): 22312.0
Avg accp length: 3.5 
input_size: 7
avg_time: 32.88,

processing spec_length = 5, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 4096
seq_thru_put: 0.483 reqs/sec, 
token_latency: 8.08 ms/token 
Peak memory usage (MiB): 21541.093098958332
Peak memory usage (including context) (MiB): 22310.0
Avg accp length: 3.2 
input_size: 7
avg_time: 33.10,

processing spec_length = 4, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 4096
seq_thru_put: 0.533 reqs/sec, 
token_latency: 7.32 ms/token 
Peak memory usage (MiB): 21541.092122395832
Peak memory usage (including context) (MiB): 22312.0
Avg accp length: 2.8 
input_size: 7
avg_time: 30.00,

processing spec_length = 3, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 4096
seq_thru_put: 0.538 reqs/sec, 
token_latency: 7.26 ms/token 
Peak memory usage (MiB): 21541.092122395832
Peak memory usage (including context) (MiB): 22312.0
Avg accp length: 2.4 
input_size: 7
avg_time: 29.73,

processing spec_length = 2, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 4096
seq_thru_put: 0.496 reqs/sec, 
token_latency: 7.87 ms/token 
Peak memory usage (MiB): 21541.091634114582
Peak memory usage (including context) (MiB): 22310.0
Avg accp length: 1.8 
input_size: 7
avg_time: 32.23,

processing spec_length = 1, draft_model = TinyLlama/TinyLlama-1.1B-Chat-v0.6 .... 
tot_gen_tokens: 4096
seq_thru_put: 0.399 reqs/sec, 
token_latency: 9.8 ms/token 
Peak memory usage (MiB): 21541.091634114582
Peak memory usage (including context) (MiB): 22312.0
Avg accp length: 1.0 
input_size: 7
avg_time: 40.14,

processing spec_length = 0, draft_model = None .... 
tot_gen_tokens: 4096
seq_thru_put: 0.596 reqs/sec, 
token_latency: 6.55 ms/token 
Peak memory usage (MiB): 21432.7958984375
Peak memory usage (including context) (MiB): 22248.0
Avg accp length: 1.0 
input_size: 7
avg_time: 26.84,
saved to /opt/mount_folder/djl-serving/engines/python/setup/djl_python/tests/rolling_batch_test_scripts/data_v2_3_1/lmi_perform_concur_16+Llama-2-70B-Chat-fp16++TinyLlama-1.1B-Chat-v0.6.p
Time elapse: 947.8773964719949s
