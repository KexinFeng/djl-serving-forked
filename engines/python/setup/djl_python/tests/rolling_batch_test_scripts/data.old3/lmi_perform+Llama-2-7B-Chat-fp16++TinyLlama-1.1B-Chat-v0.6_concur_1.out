
processing spec_length = 5 .... 
tot_gen_tokens: 100
seq_thru_put: 0.308 reqs/sec, 
token_latency: 32.5 ms/token 
Peak memory usage (MiB): 19125.6318359375
Peak memory usage (including context) (MiB): 19575.333333333332
Avg accp length: 3.0input_size: 5
avg_time: 3.2451090600031116,

processing spec_length = 4 .... 
tot_gen_tokens: 100
seq_thru_put: 0.316 reqs/sec, 
token_latency: 31.6 ms/token 
Peak memory usage (MiB): 19125.3828125
Peak memory usage (including context) (MiB): 19574.0
Avg accp length: 2.7567567567567566input_size: 5
avg_time: 3.160332771333439,

processing spec_length = 3 .... 
tot_gen_tokens: 100
seq_thru_put: 0.316 reqs/sec, 
token_latency: 31.6 ms/token 
Peak memory usage (MiB): 19125.1357421875
Peak memory usage (including context) (MiB): 19574.0
Avg accp length: 2.380952380952381input_size: 5
avg_time: 3.1602388103322787,

processing spec_length = 2 .... 
tot_gen_tokens: 100
seq_thru_put: 0.273 reqs/sec, 
token_latency: 36.7 ms/token 
Peak memory usage (MiB): 19124.951171875
Peak memory usage (including context) (MiB): 19574.0
Avg accp length: 1.7543859649122806input_size: 5
avg_time: 3.668259001332141,

processing spec_length = 1 .... 
tot_gen_tokens: 100
seq_thru_put: 0.186 reqs/sec, 
token_latency: 53.9 ms/token 
Peak memory usage (MiB): 19124.7666015625
Peak memory usage (including context) (MiB): 19574.0
Avg accp length: 1.0input_size: 5
avg_time: 5.385446189999736,

processing spec_length = 0 .... 
tot_gen_tokens: 100
seq_thru_put: 0.324 reqs/sec, 
token_latency: 30.9 ms/token 
Peak memory usage (MiB): 19134.19287109375
Peak memory usage (including context) (MiB): 19492.0
Avg accp length: 1.0input_size: 5
avg_time: 3.090798169000967,
saved to /opt/mount_folder/djl-serving/engines/python/setup/djl_python/tests/rolling_batch_test_scripts/data/lmi_perform+Llama-2-7B-Chat-fp16++TinyLlama-1.1B-Chat-v0.6_concur_1.p
Time elapse: 98.5308794800003s
