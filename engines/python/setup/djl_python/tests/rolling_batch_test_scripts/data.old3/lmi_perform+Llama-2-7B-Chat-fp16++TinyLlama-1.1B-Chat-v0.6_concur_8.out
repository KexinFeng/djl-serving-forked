
processing spec_length = 5 .... 
tot_gen_tokens: 800
seq_thru_put: 1.67 reqs/sec, 
token_latency: 5.99 ms/token 
Peak memory usage (MiB): 19151.5087890625
Peak memory usage (including context) (MiB): 19598.0
Avg accp length: 3.086792452830189input_size: 5
avg_time: 4.7896056496659485,

processing spec_length = 4 .... 
tot_gen_tokens: 800
seq_thru_put: 1.84 reqs/sec, 
token_latency: 5.44 ms/token 
Peak memory usage (MiB): 19152.03662109375
Peak memory usage (including context) (MiB): 19598.0
Avg accp length: 2.777397260273973input_size: 5
avg_time: 4.348235924335313,

processing spec_length = 3 .... 
tot_gen_tokens: 800
seq_thru_put: 1.81 reqs/sec, 
token_latency: 5.54 ms/token 
Peak memory usage (MiB): 19153.4501953125
Peak memory usage (including context) (MiB): 19596.0
Avg accp length: 2.290960451977401input_size: 5
avg_time: 4.42926357666632,

processing spec_length = 2 .... 
tot_gen_tokens: 800
seq_thru_put: 1.79 reqs/sec, 
token_latency: 5.59 ms/token 
Peak memory usage (MiB): 19151.455078125
Peak memory usage (including context) (MiB): 19598.0
Avg accp length: 1.7714285714285714input_size: 5
avg_time: 4.470773634001186,

processing spec_length = 1 .... 
tot_gen_tokens: 800
seq_thru_put: 1.34 reqs/sec, 
token_latency: 7.47 ms/token 
Peak memory usage (MiB): 19150.4375
Peak memory usage (including context) (MiB): 19616.0
Avg accp length: 1.0input_size: 5
avg_time: 5.973388315665943,

processing spec_length = 0 .... 
tot_gen_tokens: 800
seq_thru_put: 2.32 reqs/sec, 
token_latency: 4.31 ms/token 
Peak memory usage (MiB): 19143.67041015625
Peak memory usage (including context) (MiB): 19496.0
Avg accp length: 1.0input_size: 5
avg_time: 3.4457717503367653,
saved to /opt/mount_folder/djl-serving/engines/python/setup/djl_python/tests/rolling_batch_test_scripts/data/lmi_perform+Llama-2-7B-Chat-fp16++TinyLlama-1.1B-Chat-v0.6_concur_8.p
Time elapse: 116.227517471998s
