
processing spec_length = 5 .... 
tot_gen_tokens: 1600
seq_thru_put: 2.92 reqs/sec, 
token_latency: 3.42 ms/token 
Peak memory usage (MiB): 19180.67724609375
Peak memory usage (including context) (MiB): 19644.0
Avg accp length: 2.9835766423357666input_size: 5
avg_time: 5.470434044000285,

processing spec_length = 4 .... 
tot_gen_tokens: 1600
seq_thru_put: 3.16 reqs/sec, 
token_latency: 3.16 ms/token 
Peak memory usage (MiB): 19182.268717447918
Peak memory usage (including context) (MiB): 19644.0
Avg accp length: 2.7046735299573363input_size: 5
avg_time: 5.055720403664357,

processing spec_length = 3 .... 
tot_gen_tokens: 1600
seq_thru_put: 3.09 reqs/sec, 
token_latency: 3.23 ms/token 
Peak memory usage (MiB): 19183.320475260418
Peak memory usage (including context) (MiB): 19672.0
Avg accp length: 2.251619407201931input_size: 5
avg_time: 5.170783431334712,

processing spec_length = 2 .... 
tot_gen_tokens: 1600
seq_thru_put: 3.05 reqs/sec, 
token_latency: 3.28 ms/token 
Peak memory usage (MiB): 19179.96142578125
Peak memory usage (including context) (MiB): 19660.0
Avg accp length: 1.7551686615886835input_size: 5
avg_time: 5.243333091995737,

processing spec_length = 1 .... 
tot_gen_tokens: 1600
seq_thru_put: 2.32 reqs/sec, 
token_latency: 4.31 ms/token 
Peak memory usage (MiB): 19180.810546875
Peak memory usage (including context) (MiB): 19662.0
Avg accp length: 1.0input_size: 5
avg_time: 6.896643770667045,

processing spec_length = 0 .... 
tot_gen_tokens: 1600
seq_thru_put: 4.07 reqs/sec, 
token_latency: 2.46 ms/token 
Peak memory usage (MiB): 19153.63330078125
Peak memory usage (including context) (MiB): 19492.0
Avg accp length: 1.0input_size: 5
avg_time: 3.9309268796666097,
saved to /opt/mount_folder/djl-serving/engines/python/setup/djl_python/tests/rolling_batch_test_scripts/data/lmi_perform+Llama-2-7B-Chat-fp16++TinyLlama-1.1B-Chat-v0.6_concur_16.p
Time elapse: 128.87392873300269s
