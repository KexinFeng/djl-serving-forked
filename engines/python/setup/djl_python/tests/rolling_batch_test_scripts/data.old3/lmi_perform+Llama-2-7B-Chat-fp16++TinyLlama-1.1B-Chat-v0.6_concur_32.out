
processing spec_length = 5 .... 
tot_gen_tokens: 3200
seq_thru_put: 4.45 reqs/sec, 
token_latency: 2.25 ms/token 
Peak memory usage (MiB): 19245.45361328125
Peak memory usage (including context) (MiB): 19864.0
Avg accp length: 3.0132104454685096input_size: 5
avg_time: 7.194583940666537,

processing spec_length = 4 .... 
tot_gen_tokens: 3200
seq_thru_put: 5.12 reqs/sec, 
token_latency: 1.95 ms/token 
Peak memory usage (MiB): 19245.42919921875
Peak memory usage (including context) (MiB): 19948.0
Avg accp length: 2.7297979797979797input_size: 5
avg_time: 6.252185726329723,

processing spec_length = 3 .... 
tot_gen_tokens: 3200
seq_thru_put: 4.99 reqs/sec, 
token_latency: 2 ms/token 
Peak memory usage (MiB): 19247.134765625
Peak memory usage (including context) (MiB): 20052.0
Avg accp length: 2.2579972183588315input_size: 5
avg_time: 6.411137076332428,

processing spec_length = 2 .... 
tot_gen_tokens: 3200
seq_thru_put: 4.74 reqs/sec, 
token_latency: 2.11 ms/token 
Peak memory usage (MiB): 19241.1015625
Peak memory usage (including context) (MiB): 20038.0
Avg accp length: 1.7618787547788093input_size: 5
avg_time: 6.746265630332346,

processing spec_length = 1 .... 
tot_gen_tokens: 3200
seq_thru_put: 3.55 reqs/sec, 
token_latency: 2.81 ms/token 
Peak memory usage (MiB): 19238.2197265625
Peak memory usage (including context) (MiB): 20148.0
Avg accp length: 1.0input_size: 5
avg_time: 9.001945908334164,

processing spec_length = 0 .... 
tot_gen_tokens: 3200
seq_thru_put: 6.35 reqs/sec, 
token_latency: 1.57 ms/token 
Peak memory usage (MiB): 19170.02294921875
Peak memory usage (including context) (MiB): 19514.0
Avg accp length: 1.0input_size: 5
avg_time: 5.0360308740006685,
saved to /opt/mount_folder/djl-serving/engines/python/setup/djl_python/tests/rolling_batch_test_scripts/data/lmi_perform+Llama-2-7B-Chat-fp16++TinyLlama-1.1B-Chat-v0.6_concur_32.p
Time elapse: 155.6383675180041s
