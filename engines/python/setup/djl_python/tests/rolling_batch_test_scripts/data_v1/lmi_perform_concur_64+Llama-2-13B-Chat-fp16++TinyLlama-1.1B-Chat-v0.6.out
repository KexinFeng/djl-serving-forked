
processing spec_length = 0.0, draft_model = None .... 
tot_gen_tokens: 6400
seq_thru_put: 9 reqs/sec, 
token_latency: 1.11 ms/token 
Peak memory usage (MiB): 20618.66748046875
Peak memory usage (including context) (MiB): 22020.8125
Avg accp length: 1.0input_size: 5
avg_time: 7.114758588666518,

processing spec_length = 0.0, draft_model = None .... 
tot_gen_tokens: 6400
seq_thru_put: 9.01 reqs/sec, 
token_latency: 1.11 ms/token 
Peak memory usage (MiB): 20621.79248046875
Peak memory usage (including context) (MiB): 22020.8125
Avg accp length: 1.0input_size: 5
avg_time: 7.104768531333018,

processing spec_length = 0.0, draft_model = None .... 
tot_gen_tokens: 6400
seq_thru_put: 9.02 reqs/sec, 
token_latency: 1.11 ms/token 
Peak memory usage (MiB): 20621.79248046875
Peak memory usage (including context) (MiB): 22020.8125
Avg accp length: 1.0input_size: 5
avg_time: 7.099099150666613,

processing spec_length = 0.0, draft_model = None .... 
tot_gen_tokens: 6400
seq_thru_put: 9.01 reqs/sec, 
token_latency: 1.11 ms/token 
Peak memory usage (MiB): 20621.79248046875
Peak memory usage (including context) (MiB): 22020.8125
Avg accp length: 1.0input_size: 5
avg_time: 7.103290917666527,

processing spec_length = 0.0, draft_model = None .... 
tot_gen_tokens: 6400
seq_thru_put: 9.02 reqs/sec, 
token_latency: 1.11 ms/token 
Peak memory usage (MiB): 20621.79248046875
Peak memory usage (including context) (MiB): 22020.8125
Avg accp length: 1.0input_size: 5
avg_time: 7.093801466333389,

processing spec_length = 0.0, draft_model = None .... 
tot_gen_tokens: 6400
seq_thru_put: 9.04 reqs/sec, 
token_latency: 1.11 ms/token 
Peak memory usage (MiB): 20621.79248046875
Peak memory usage (including context) (MiB): 22020.8125
Avg accp length: 1.0input_size: 5
avg_time: 7.079838380333361,
saved to /opt/mount_folder/djl-serving/engines/python/setup/djl_python/tests/rolling_batch_test_scripts/data/lmi_perform_concur_64+Llama-2-13B-Chat-fp16++TinyLlama-1.1B-Chat-v0.6.p
Time elapse: 167.71098280800015s
